# 过拟合和欠拟合及其解决方案

训练误差(training error)，是指模型在训练数据集上的表现。

泛化误差(generalization error)，是指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。（通常将在测试集上的误差当作泛化误差）

## 模型选择

### 验证数据集

测试集只能在所有超参数和模型参数选定后使用一次。不能将测试集作为调参的基础。模型的泛化能力不能从测试集上进行泛化，故在选择模型时，不能只依赖测试损失。因此，我们可以在训练和测试数据以外找一个数据集作为验证数据，这部分数据集称之为验证数据集。例如，可以从给定的训练数据集中，提前随机选取一小部分作为验证集，剩余的部分作为训练集。

### K折交叉验证

当训练数据较少时，预留大量的验证集太奢侈，可以使用k-折交叉验证（k-fold cross-validation）。k-折交叉验证，把原始训练集分成k个不重合的子集；然后，做k次训练验证，每次使用k-1个子集作为训练，1个作为验证。经过k次后，每个子集都充当了验证集和训练集；最后，求k次的训练和验证损失做为最终的损失。

## 过拟合和欠拟合

在模型的训练中存在两个经典问题：

- 欠拟合（underfitting），模型无法得到较低的训练误差，即在训练和预测时表现很差。
- 过拟合（overdefitting），模型的训练误差小于模型的测试误差，即模型在训练数据集上表现很好，在泛化时表现很差。表明模型学到的特征是训练数据集的个有特征，没有代表性。

## 模型复杂度

![](C:\Users\Administrator\Desktop\q5jc27wxoj.png)****

从图中可以看出，模型复杂度越高，出现过拟合的可能性越大，反之，则容易出现欠拟合。

## 降低—过拟合—的方法

- **增加训练数据**。增加训练数据，可以使模型在更多的样本中学习到更多有效的特征，减少噪声的影响。

- **降低模型的复杂度**。在数据较少时，模型过于复杂是产生过拟合的主要原因，适当降低模型复杂度可以避免模型拟合过多的噪声。

- **正则化，给模型的参数加上一定的正则约束**。比如将权值的大小加入到损失函数中。以$L_2$范数正则化为例，其是在模型原损失函数基础上添加$L_2$范数惩罚项，从而使得训练所需要最小化的函数。$L_2$范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。以线性回归损失函数为例：
  $$
  \ell(w_1,w_2,b)=\frac{1}{n}\sum^{n}_{i=1}\frac{1}{2}(x^{(i)}_1w_1+x^{(i)}_2w_2+b-y^{(i)})^2
  $$
  其中，$w_1,w_2$为去找权重参数，$b$为偏置项，样本$i$的输入为为$x_1^{i},x_2^{i}$，标签为$y^{(i)}$，样本数为$n$。将权重参数用向量$W=[w_1,w_2]$表示，带有$L_2$范数惩罚项的损失函数为：
  $$
  \ell(w_1,w_2,b)+\frac{\lambda}{2n}|W|^2
  $$
  其中，$\lambda>0$为超参数。当权重参数均小于0是，**惩罚项最小**。当$\lambda$较大时，惩罚项在损失函数中占比较大，这使得学习到的权重参数更趋近与0。当$\lambda$设为0时，惩罚项没有作用。上式中$L_2$范数平方$|W|^2$展开后得到$w_{1}^{2}+w_{2}^{2}$。有了$L_2$范数惩罚项后，在小批量随机梯度下降中，将线性回归中的参数迭代方式更改为：
  $$
  \begin{align}
   w_1 \leftarrow (1-\frac{n\lambda}{|B|})w_1-\frac{n}{|B|}\sum_{i\in B}x^{i}_{1}(x^{i}_{1}w_1+x^{i}_{2}w_2+b-y^{(i)})^2  \\ w_2 \leftarrow (1-\frac{n\lambda}{|B|})w_2-\frac{n}{|B|}\sum_{i\in B}x^{i}_{2}(x^{i}_{1}w_1+x^{i}_{2}w_2+b-y^{(i)})^2 
  \end{align}
  $$
  可以看出，$L_2$范数正则化令权重$w_1$和$w_2$先自乘小于1的数，再减去不含惩罚项的地图。因此，$L_2$范数正则化又叫权重衰减。